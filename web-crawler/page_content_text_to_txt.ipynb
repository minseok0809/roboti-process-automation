{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Content Text to TXT (Beautifulsoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import urllib\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve, urlopen\n",
    "from urllib.error import URLError, HTTPError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page Title & Link Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_page_title_link_description_list(soup):\n",
    "\n",
    "    pre_title_list = []\n",
    "    title_list = []\n",
    "    link_list = []\n",
    "\n",
    "    a = soup.select(\"a\")\n",
    "    for a_text in a:\n",
    "        a_text = str(a_text)\n",
    "\n",
    "        if 'pages/articles' in a_text:\n",
    "            a_title = re.search('\">(.+?)</a>', a_text)\n",
    "            if a_title != None:\n",
    "                a_title = a_title.group()\n",
    "                a_title = a_title.replace('\">', '')\n",
    "                a_title = a_title.replace('<a>', '')\n",
    "                a_title = a_title.replace(' </a>', '')\n",
    "                a_title = a_title.replace(\"?\", \"\")\n",
    "                a_title = a_title.replace(\":\", \"\")\n",
    "                a_title = a_title.replace(\"/\", \"\")\n",
    "                pre_title_list.append(a_title)\n",
    "\n",
    "            a_link = re.search('<a href=(.+?)\">', a_text)\n",
    "            if a_link != None:\n",
    "                a_link = a_link.group()\n",
    "                a_link = a_link.replace('<a href=\"', 'https://www.pressian.com')\n",
    "                a_link = a_link.replace('\">', '')\n",
    "                link_list.append(a_link)\n",
    "                link_list = dict.fromkeys(link_list)\n",
    "                link_list = list(link_list)\n",
    "\n",
    "    for i in range(0, len(pre_title_list)):\n",
    "        if len(pre_title_list[i]) <= 30:\n",
    "            pre_title_list[i] = pre_title_list[i].replace('<a>', '')\n",
    "            title_list.append(pre_title_list[i])\n",
    "\n",
    "    return title_list, link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_total_page_title_link_list(link_pattern, number_of_page):\n",
    "\n",
    "    total_title_list = []\n",
    "    total_link_list = []\n",
    "\n",
    "    # query = urllib.parse.quote('keyword')\n",
    "    for page_num in range(number_of_page):\n",
    "        \n",
    "        url = link_pattern +  str(page_num + 1) # + query\n",
    "\n",
    "        try:\n",
    "            request = urllib.request.Request(url)\n",
    "\n",
    "            response = urllib.request.urlopen(request)\n",
    "            response_code = response.getcode()\n",
    "\n",
    "            if response_code == 200:\n",
    "                response_body = response.read()\n",
    "\n",
    "            soup = BeautifulSoup(response_body, 'html.parser') \n",
    "\n",
    "            title_list, link_list  = make_page_title_link_description_list(soup)\n",
    "\n",
    "            total_title_list.append(title_list)\n",
    "            total_link_list.append(link_list)\n",
    "\n",
    "        except HTTPError as e:\n",
    "            err = e.read()\n",
    "            code = e.getcode()\n",
    "            print(\"The number of page:\", page_num - 1) \n",
    "            print(\"Error Code:\", code)\n",
    "            print(\"\\n\")\n",
    "            break\n",
    "\n",
    "    total_title_list = sum(total_title_list, [])\n",
    "    total_link_list = sum(total_link_list, [])\n",
    "\n",
    "    return total_title_list, total_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_page_title_link_df(titles, links):\n",
    "    \n",
    "    page_title_link_df = pd.DataFrame({'title':titles, 'link':links})\n",
    "    \n",
    "    return page_title_link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_pattern = 'https://www.pressian.com/pages/serials/1240?page='\n",
    "number_of_page = 10\n",
    "\n",
    "page_title_link_df = pd.DataFrame({'title':[\"title\"], 'link':[\"link\"]})\n",
    "\n",
    "title_list, link_list = make_total_page_title_link_list(link_pattern, number_of_page)\n",
    "part_page_title_link_df = make_page_title_link_df(title_list, link_list)\n",
    "page_title_link_df = pd.concat([page_title_link_df, part_page_title_link_df])\n",
    "\n",
    "page_title_link_df = page_title_link_df.reset_index()\n",
    "del page_title_link_df['index']\n",
    "page_title_link_df = page_title_link_df.drop(page_title_link_df.index[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>최후의 질문</td>\n",
       "      <td>https://www.pressian.com/pages/articles/56653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>논리와 결정불가능성</td>\n",
       "      <td>https://www.pressian.com/pages/articles/56652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가치관념과 과학의 발전</td>\n",
       "      <td>https://www.pressian.com/pages/articles/56651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>과학과 사회</td>\n",
       "      <td>https://www.pressian.com/pages/articles/56650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>과학의 위험성</td>\n",
       "      <td>https://www.pressian.com/pages/articles/56649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>보편 이론체계와 대칭성 깨짐</td>\n",
       "      <td>https://www.pressian.com/pages/articles/54924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>좋은 이론이란</td>\n",
       "      <td>https://www.pressian.com/pages/articles/54921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>과학적 사고란</td>\n",
       "      <td>https://www.pressian.com/pages/articles/54811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>과학은 아름답다</td>\n",
       "      <td>https://www.pressian.com/pages/articles/54810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>과학은 물질적 번영을 위한 도구일 뿐인가</td>\n",
       "      <td>https://www.pressian.com/pages/articles/54809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                                           link\n",
       "1                   최후의 질문  https://www.pressian.com/pages/articles/56653\n",
       "2               논리와 결정불가능성  https://www.pressian.com/pages/articles/56652\n",
       "3             가치관념과 과학의 발전  https://www.pressian.com/pages/articles/56651\n",
       "4                   과학과 사회  https://www.pressian.com/pages/articles/56650\n",
       "5                  과학의 위험성  https://www.pressian.com/pages/articles/56649\n",
       "..                     ...                                            ...\n",
       "86         보편 이론체계와 대칭성 깨짐  https://www.pressian.com/pages/articles/54924\n",
       "87                 좋은 이론이란  https://www.pressian.com/pages/articles/54921\n",
       "88                 과학적 사고란  https://www.pressian.com/pages/articles/54811\n",
       "89                과학은 아름답다  https://www.pressian.com/pages/articles/54810\n",
       "90  과학은 물질적 번영을 위한 도구일 뿐인가  https://www.pressian.com/pages/articles/54809\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "page_title_link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_title_link_df.to_excel('page_title_link_df.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page Content Text to TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_page_content_text(url):\n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "\n",
    "    response = urllib.request.urlopen(request)\n",
    "    response_code = response.getcode()\n",
    "\n",
    "    if response_code == 200:\n",
    "        response_body = response.read()\n",
    "\n",
    "    soup = BeautifulSoup(response_body, 'html.parser') \n",
    "\n",
    "    content_list = []\n",
    "\n",
    "    a = soup.select(\"div\")\n",
    "    for a_text in a:\n",
    "        a_text = str(a_text)\n",
    "\n",
    "        if '<br/>' in a_text:\n",
    "            a_content = re.search('<br/>(.+?)<br/><table align=\"center\"', a_text)\n",
    "            if a_content != None:\n",
    "                a_content = a_content.group()\n",
    "                a_content = re.sub(r\"\\<.*?\\>\", \"\", a_content)\n",
    "                a_content = a_content.replace('<table align=\"center\"', '')\n",
    "                content_list.append(a_content)\n",
    "\n",
    "            b_content = re.search('<br/>(.+?)<br/><font color=', a_text)\n",
    "            if b_content != None:\n",
    "                b_content = b_content.group()\n",
    "                b_content = re.sub(r\"\\<.*?\\>\", \"\", b_content)\n",
    "                b_content = b_content.replace('<font color=', '')\n",
    "                content_list.append(b_content)   \n",
    "\n",
    "    content_dict = dict.fromkeys(content_list)\n",
    "    content_list = list(content_dict)  \n",
    "    content_text = \" \".join(content_list)\n",
    "\n",
    "    return content_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_series = page_title_link_df['title']\n",
    "link_series = page_title_link_df['link']\n",
    "\n",
    "for title, link in zip(title_series, link_series):\n",
    "    content_text = make_page_content_text(link)\n",
    "    with open(title + \".txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 자연현상은 그 현상의 실체인 물질의 구성원 사이의 상호작용 때문에 생긴다고 했습니다\n",
      " 간단한 예로 공을 던졌을 때 포물선을 그리며 날아가는 것도 자연현상입니다\n",
      " 공이라는 구성원과 지구라는 구성원 사이의 상호작용, 곧 중력에 의해 어떻게 날아갈지 운동이 정해집니다\n",
      " 마찬가지로 어떤 것은 딱딱하고 어떤 것은 물렁물렁하고 어떤 것은 빨갛고 혹은 파랗고 어떤 것은 반짝이고 등 물건의 성질도 모두 자연현상입니다\n",
      "그런 것을 이해하고 해석하려면 그 물건의 구성원, 즉 분자를 생각해야 합니다\n"
     ]
    }
   ],
   "source": [
    "line_num = 0\n",
    "with open('동역학.txt', 'r') as f:\n",
    "    lines = f.read()\n",
    "    lines = lines.split(\".\")\n",
    "    for line in lines:\n",
    "        line_num += 1\n",
    "        if line_num <= 5:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Content TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = glob.glob(\"*.txt\")\n",
    "with open(\"최무영의 과학이야기.txt\", 'w', encoding='utf-8') as f:\n",
    "    for corpus in corpus_list:\n",
    "        with open(corpus, encoding='utf-8') as text:\n",
    "            for line in text:\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Github</b>\n",
    "<br>cheris8\n",
    "<br>[동적 웹 페이지 크롤링 with Python](https://cheris8.github.io/data%20analysis/DC-Dynamic-Webpage-Crawling/)\n",
    "\n",
    "<br><b>News</b>\n",
    "<br>[프레시안 <최무영의 과학이야기>](https://www.pressian.com/pages/serials/1240)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
