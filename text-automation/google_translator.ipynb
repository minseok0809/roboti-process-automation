{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install googletrans==4.0.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from PyPDF2 import PdfReader\n",
    "from googletrans import Translator\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extractor_from_pdf(paper_path):\n",
    "    \n",
    "    reader = PdfReader(paper_path)\n",
    "    paper_pages = reader.pages\n",
    "\n",
    "    total_text_list = []\n",
    "\n",
    "    for paper_page in paper_pages:\n",
    "\n",
    "        pdf_paragrpah = paper_page.extract_text().split(\"\\n\")\n",
    "\n",
    "        for pdf_text in pdf_paragrpah:\n",
    "            total_text_list.append(pdf_text)\n",
    "\n",
    "    return total_text_list\n",
    "\n",
    "def reference_extractor_from_text(total_text_list, save_txt_path):\n",
    "\n",
    "    reference_text = \"\"\n",
    "    reference_text_list = []\n",
    "    begin_refrence_index = 0\n",
    "    end_refrence_index = 0\n",
    "\n",
    "    for index, text in enumerate(total_text_list):\n",
    "\n",
    "        if text.lower() == \"abstract\":\n",
    "            begin_refrence_index = index\n",
    "\n",
    "        elif text.lower() == \"references\":\n",
    "            end_refrence_index = index + 1\n",
    "\n",
    "    for index, text in enumerate(total_text_list):\n",
    "\n",
    "        if index >= begin_refrence_index and index < end_refrence_index:\n",
    "            reference_text_list.append(text) \n",
    "            reference_text += text + \"\\n\"\n",
    "\n",
    "    for idx, value in enumerate(reference_text_list):\n",
    "        if value.lower() == \"abstract\":\n",
    "            start_idx = idx\n",
    "\n",
    "    reference_text_list = reference_text_list[start_idx:]\n",
    "\n",
    "    with open(save_txt_path, 'a', encoding='utf-8') as fp:\n",
    "        fp.write(\"\\n\".join(reference_text_list))\n",
    "\n",
    "    return reference_text\n",
    "\n",
    "def reference_extractor_from_pdf(paper_path, save_txt_path):\n",
    "\n",
    "    total_text_list = text_extractor_from_pdf(paper_path)\n",
    "    reference_text = reference_extractor_from_text(total_text_list, save_txt_path)\n",
    "\n",
    "    return reference_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Google_Translator:\n",
    "    def __init__(self):\n",
    "        self.translator = Translator()\n",
    "        self.result = {'src_text': '', 'src_lang': '', 'tgt_text': '', 'tgt_lang': ''}\n",
    " \n",
    "    def translate(self, text, lang='en'):\n",
    "        translated = self.translator.translate(text, dest=lang)\n",
    "        self.result['src_text'] = translated.origin\n",
    "        self.result['src_lang'] = translated.src\n",
    "        self.result['tgt_text'] = translated.text\n",
    "        self.result['tgt_lang'] = translated.dest\n",
    " \n",
    "        return self.result\n",
    " \n",
    "    def translate_file(self, load_path, save_path, lang='en'):\n",
    "        with open(load_path, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = text.replace(\"\\n\", \"\")\n",
    "            sentence_list = sent_tokenize(text)\n",
    "        \n",
    "        translation = []\n",
    "        for sentence in sentence_list:\n",
    "            result = self.translate(sentence, lang)['tgt_text']\n",
    "            translation.append(result) \n",
    "\n",
    "        with open(save_path, 'a', encoding='utf-8') as fp:\n",
    "            fp.write(\"\\n\".join(translation))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_path = \"Attention is all you need.pdf\"\n",
    "save_txt_path = \"Attention is all you need.txt\"\n",
    "reference_text = reference_extractor_from_pdf(paper_path, save_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Google_Translator()\n",
    "tgt_lang_code = 'ko'\n",
    "\n",
    "load_path = \"Attention is all you need.txt\"\n",
    "save_path = \"Attention is all you need (Ko).txt\"\n",
    "translator.translate_file(load_path, save_path, tgt_lang_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Paper</b>\n",
    "<br>[Vaswani et al. Attention Is All You Need. NeurIPS, 2017.](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "<br><br><b>Github</b>\n",
    "<br>yunwoong7\n",
    "<br>[translator](https://github.com/yunwoong7/translator)\n",
    "\n",
    "<br>ssut\n",
    "<br>[TypeError: the JSON object must be str, bytes or bytearray, not NoneType](https://github.com/ssut/py-googletrans/issues/301)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
